{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Reads and reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the kmer table\n",
    "import sys\n",
    "sys.path.append('/home/djjoshi')\n",
    "import all_functions as func\n",
    "import numpy as np\n",
    "import Levenshtein as L\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "kmermap = func.get_kmer_map('/home/djjoshi/r9.4_6mer_nucleotide_template_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/djjoshi/nanopore_bioinformatics', '/home/djjoshi/anaconda3/lib/python37.zip', '/home/djjoshi/anaconda3/lib/python3.7', '/home/djjoshi/anaconda3/lib/python3.7/lib-dynload', '', '/home/djjoshi/anaconda3/lib/python3.7/site-packages', '/home/djjoshi/anaconda3/lib/python3.7/site-packages/IPython/extensions', '/home/djjoshi/.ipython', '/home/djjoshi']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_reads = 50000\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Get Reads\n",
    "folder = 'expt2_MinION/'\n",
    "reads,num_reads,name = func.get_reads_from_fasta(folder+'reads.fasta')\n",
    "print(len(reads))\n",
    "print(num_reads)\n",
    "\n",
    "# reads2,num_reads2,_ = func.get_reads_from_fastq(folder+'ERR2683661.fastq')\n",
    "# print(len(reads2))\n",
    "# print(num_reads2)\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Reads from memory\n",
    "folder = './'\n",
    "import pickle\n",
    "with open(folder+'reads.txt','rb') as f:\n",
    "    reads = pickle.load(f)\n",
    "num_reads = len(reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump reads to pickle file\n",
    "folder = './'\n",
    "import pickle\n",
    "with open('reads_1.p','wb') as f:\n",
    "    pickle.dump(reads1,f)\n",
    "with open('reads_2.p','wb') as f:\n",
    "    pickle.dump(reads2,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all reads\n",
    "all_reads = reads1+reads2\n",
    "del reads1,reads2\n",
    "print(len(all_reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample reads without replacement\n",
    "idx = np.random.choice(len(reads1),50000,replace=False)\n",
    "r=[]\n",
    "r_length = 0\n",
    "for i in idx:\n",
    "    r.append(reads1[i])\n",
    "    r_length+=len(reads1[i])\n",
    "reads = r\n",
    "del r,reads1\n",
    "num_reads = len(reads)\n",
    "print('num_reads = '+str(num_reads))\n",
    "print('Average read length = {:.2f}'.format(r_length/num_reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total genomes = 25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Get reference genome\n",
    "ref,num_ref,name = func.get_genome_from_fasta('GRCh38_ref.fasta')\n",
    "print(num_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the primary chromosome index\n",
    "names_index = []\n",
    "new_names = []\n",
    "for i in range(len(name)):\n",
    "    if name[i][:3] == '>NC':\n",
    "        names_index.append(i)\n",
    "print(len(names_index))\n",
    "for i in range(len(names_index)):\n",
    "    if i<22:\n",
    "        new_names.append('>ref_chr_'+str(i+1)+'\\n')\n",
    "    elif i==22:\n",
    "        new_names.append('>ref_chr_X\\n')\n",
    "    elif i==23:\n",
    "        new_names.append('>ref_chr_Y\\n')\n",
    "    elif i==24:\n",
    "        new_names.append('>ref_chr_M\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new ref from all ref\n",
    "new_ref = []\n",
    "for i in range(len(names_index)):\n",
    "    new_ref.append(ref[names_index[i]])\n",
    "print(len(new_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print new ref to fasta\n",
    "func.print_ref_to_fasta(new_ref,'GRCh38_ref.fasta',new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Chr_21 to fasta\n",
    "ref1 = []\n",
    "ref1 = [new_ref[0]]\n",
    "func.print_ref_to_fasta(ref1,'ref_chr1.fasta',[new_names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(new_ref[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the approximate alignments and choose the reads to be used for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the paf file\n",
    "approx_mapping_60,_ = func.extract_from_paf('approx_mapping_60.paf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.where(approx_mapping_60[:,7]>10000000)[0]\n",
    "b = np.where(approx_mapping_60[:,8]<20000000)[0]\n",
    "c = np.intersect1d(a,b)\n",
    "print(c.shape)\n",
    "d = np.unique(approx_mapping_60[c,0])\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the read index aligning to the genome section of interest\n",
    "index = []\n",
    "for name in name1:\n",
    "    name = name.split(' ')\n",
    "    name = name[0]\n",
    "    name = name.split('.')\n",
    "    name = int(name[1])\n",
    "    if name in d:\n",
    "        index.append(name)\n",
    "print(len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads = []\n",
    "name = []\n",
    "for i in index:\n",
    "    reads.append(reads1[i-1])\n",
    "    name.append('>read_'+str(i)+'\\n')\n",
    "print(len(reads))\n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the reads to the fasta file\n",
    "func.print_reads_to_fasta(reads,'reads.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_mapping_60[55,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting ACGT reads to Quantized reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the read file\n",
    "reads,num_reads,name = func.get_reads_from_fasta('reads_60.fasta')\n",
    "print(num_reads)\n",
    "print(len(reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find average read length\n",
    "read_length = 0\n",
    "for i in range(num_reads):\n",
    "    read_length+=len(reads[i])\n",
    "print('Average read length = {}'.format(read_length//num_reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get complement reads\n",
    "c_reads = [None]*num_reads\n",
    "for i in range(0,num_reads):\n",
    "    c_reads[i] = func.complement(reads[i])\n",
    "print(len(c_reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Current reads\n",
    "import numpy as np\n",
    "kmer_k = 6\n",
    "current_reads = [None]*num_reads\n",
    "rc_current_reads = [None]*num_reads\n",
    "for i in range(0,num_reads):\n",
    "    for k in range(0,2):\n",
    "        seq = reads[i]\n",
    "        if(k==1):\n",
    "            seq = func.revcom(seq)\n",
    "        current_mean = np.zeros(len(seq)-kmer_k+1)\n",
    "        for j in range(0,len(seq)-kmer_k+1):\n",
    "            current_mean[j] = kmermap[seq[j:j+6]][0]\n",
    "        if(k==0):\n",
    "            current_reads[i] = current_mean\n",
    "        else:\n",
    "            rc_current_reads[i] = current_mean\n",
    "        current_mean = []\n",
    "    if(i%1000==0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total genomes = 25\n",
      "25\n",
      "25\n",
      "['>ref_chr_1\\n', '>ref_chr_2\\n', '>ref_chr_3\\n', '>ref_chr_4\\n', '>ref_chr_5\\n', '>ref_chr_6\\n', '>ref_chr_7\\n', '>ref_chr_8\\n', '>ref_chr_9\\n', '>ref_chr_10\\n', '>ref_chr_11\\n', '>ref_chr_12\\n', '>ref_chr_13\\n', '>ref_chr_14\\n', '>ref_chr_15\\n', '>ref_chr_16\\n', '>ref_chr_17\\n', '>ref_chr_18\\n', '>ref_chr_19\\n', '>ref_chr_20\\n', '>ref_chr_21\\n', '>ref_chr_22\\n', '>ref_chr_X\\n', '>ref_chr_Y\\n', '>ref_chr_M\\n']\n"
     ]
    }
   ],
   "source": [
    "# Load the reference file\n",
    "ref,num_ref,name_ref = func.get_genome_from_fasta('/home/djjoshi/GRCh38_ref.fasta')\n",
    "print(len(ref))\n",
    "print(num_ref)\n",
    "print(name_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000 out of 248956422\n",
      "200000000 out of 248956422\n",
      "Completed chromosome 1 of 25\n",
      "100000000 out of 242193529\n",
      "200000000 out of 242193529\n",
      "Completed chromosome 2 of 25\n",
      "100000000 out of 198295559\n",
      "Completed chromosome 3 of 25\n",
      "100000000 out of 190214555\n",
      "Completed chromosome 4 of 25\n",
      "100000000 out of 181538259\n",
      "Completed chromosome 5 of 25\n",
      "100000000 out of 170805979\n",
      "Completed chromosome 6 of 25\n",
      "100000000 out of 159345973\n",
      "Completed chromosome 7 of 25\n",
      "100000000 out of 145138636\n",
      "Completed chromosome 8 of 25\n",
      "100000000 out of 138394717\n",
      "Completed chromosome 9 of 25\n",
      "100000000 out of 133797422\n",
      "Completed chromosome 10 of 25\n",
      "100000000 out of 135086622\n",
      "Completed chromosome 11 of 25\n",
      "100000000 out of 133275309\n",
      "Completed chromosome 12 of 25\n",
      "100000000 out of 114364328\n",
      "Completed chromosome 13 of 25\n",
      "100000000 out of 107043718\n",
      "Completed chromosome 14 of 25\n",
      "100000000 out of 101991189\n",
      "Completed chromosome 15 of 25\n",
      "Completed chromosome 16 of 25\n",
      "Completed chromosome 17 of 25\n",
      "Completed chromosome 18 of 25\n",
      "Completed chromosome 19 of 25\n",
      "Completed chromosome 20 of 25\n",
      "Completed chromosome 21 of 25\n",
      "Completed chromosome 22 of 25\n",
      "100000000 out of 156040895\n",
      "Completed chromosome 23 of 25\n",
      "Completed chromosome 24 of 25\n",
      "0 out of 16569\n",
      "Completed chromosome 25 of 25\n"
     ]
    }
   ],
   "source": [
    "# Get current reference\n",
    "num_ref = len(ref)\n",
    "current_ref = [None]*num_ref\n",
    "kmer_k = 6\n",
    "for i in range(0,num_ref):\n",
    "    seq = ref[i]\n",
    "    current_mean = np.zeros(len(seq)-kmer_k+1)\n",
    "    for j in range(0,len(seq)-kmer_k+1):\n",
    "        if 'N' in seq[j:j+6] or 'M' in seq[j:j+6] or 'R' in seq[j:j+6]:\n",
    "            continue\n",
    "        try:\n",
    "            current_mean[j] = kmermap[seq[j:j+6].upper()][0]\n",
    "        except:\n",
    "            continue\n",
    "        if j%100000000 == 0:\n",
    "            print('{} out of {}'.format(j,len(seq)))\n",
    "    current_ref[i] = current_mean\n",
    "    current_mean = []\n",
    "    print('Completed chromosome {} of {}'.format(i+1,len(ref)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 58.505586,  90.689915, 119.702775]), array([ 58.505586,  83.769336,  97.551224, 119.702775]), array([ 58.505586,  80.58593 ,  90.689915, 100.656871, 119.702775])]\n"
     ]
    }
   ],
   "source": [
    "# Get quantized levels\n",
    "folder = '/home/djjoshi/'\n",
    "Read_qlevels = 1\n",
    "level = [2,3,4]\n",
    "if(Read_qlevels==1):\n",
    "    import pickle\n",
    "    with open(folder+'qlevels.txt','rb') as f:\n",
    "        qlevels = pickle.load(f)\n",
    "    print(qlevels)\n",
    "else:\n",
    "    qlevels = [None]*len(level)\n",
    "    #temp_ref = current_ref[:]\n",
    "    for i in range(0,len(level)):\n",
    "        qlevels[i] = func.get_quantize_level(current_ref[0],level[i])\n",
    "    print(qlevels)\n",
    "    import pickle\n",
    "    with open(folder+'qlevels.txt','wb') as f:\n",
    "        pickle.dump(qlevels,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get quantized reads and print it to fasta file\n",
    "folder = './'\n",
    "for i in range(0,len(level)):\n",
    "    print('Quantizing to level {}'.format(level[i]))\n",
    "    reads_q = []\n",
    "    rc_reads_q = []\n",
    "    for j in range(0,num_reads):\n",
    "        reads_q+=[func.get_quantized_seq(current_reads[j],qlevels[i])]\n",
    "        rc_reads_q+=[func.get_quantized_seq(rc_current_reads[j],qlevels[i])]\n",
    "        if j%1000 == 0:\n",
    "            print('Quantizing read {} of {}'.format(j,len(reads)))\n",
    "    func.print_reads_to_fasta(reads_q,folder+'reads_q'+str(level[i])+'.fasta')\n",
    "    func.print_reads_to_fasta(rc_reads_q,folder+'rc_reads_q'+str(level[i])+'.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get quantized ref and print it to fasta file\n",
    "for i in range(0,len(level)):\n",
    "    ref_q=[]\n",
    "    for j in range(0,num_ref):\n",
    "        ref_q+=[func.get_quantized_seq(current_ref[j],qlevels[i])]\n",
    "    func.print_ref_to_fasta(ref_q,'ref_q'+str(level[i])+'.fasta',name_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print reads to fasta files\n",
    "#func.print_reads_to_fasta(reads,folder+'reads.fasta')\n",
    "func.print_reads_to_fasta(c_reads,folder+'c_reads.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reads and reference files\n",
    "import pickle\n",
    "with open(folder+'reads.txt','wb') as f:\n",
    "    pickle.dump(reads,f)\n",
    "#with open(folder+'ref.txt','wb') as f:\n",
    "#    pickle.dump(ref,f)\n",
    "\n",
    "# To load the lists use the following:\n",
    "# with open('reads.txt', 'rb') as f:\n",
    "#     reads = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test new quantization function\n",
    "import time\n",
    "%timeit r1 = func.get_quantized_sequences(current_reads[0],qlevels[2])\n",
    "%timeit r2 = func.get_quantized_seq(current_reads[0],qlevels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_reads = 50000\n",
      "Total_reads = 50000\n",
      "6886\n",
      "9551\n",
      "6886\n",
      "9551\n"
     ]
    }
   ],
   "source": [
    "############### Analysis #####################\n",
    "reads,_,_ = func.get_reads_from_fasta(folder+'reads_q2.fasta')\n",
    "rc_reads,_,_ = func.get_reads_from_fasta(folder+'rc_reads_q2.fasta')\n",
    "print(len(reads[541]))\n",
    "print(len(reads[853]))\n",
    "print(len(rc_reads[541]))\n",
    "print(len(rc_reads[853]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "rc_r = []\n",
    "r.append(reads[541])\n",
    "r.append(reads[853])\n",
    "rc_r.append(rc_reads[541])\n",
    "rc_r.append(rc_reads[853])\n",
    "print(len(r))\n",
    "print(len(rc_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "func.print_reads_to_fasta(r,'test.fasta')\n",
    "func.print_reads_to_fasta(rc_r,'test_rc.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
